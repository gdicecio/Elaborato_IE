\chapter{Web Server - Workload Characterization}
L'obiettivo dell'homework è quello di realizzare un workload sintetico semplice e ripetibile, sulla base di un workload reale, attraverso le tecniche descritte nei capitoli precedenti. Successivamente esso deve essere applicato al sistema e, infine, si deve dimostrare che statisticamente si ottiene lo stesso risultato di un workload reale. L'esperimento può essere descritto in tre fasi:
\begin{enumerate}
	\item \textit{Simulazione di un workload reale}. In questa fase si simulano delle richieste random con carico prefissato al sistema. Si collezionano quindi i dati del client (lista delle richieste) di "alto livello" e i dati del server (memoria, utilizzo della CPU, ecc.) di "basso livello". Alla fine di questa fase bisogna analizzare i dati di alto livello per costruire un workload sintetico.
	\item \textit{Applicazione di un workload sintetico}. Dopo aver ricavato il workload sintetico al termine della fase precedente, esso deve essere applicato al sistema. Nuovamente quindi devono essere collezionati i dati di alto livello e basso livello.
	\item \textit{Validazione dei dati}. Prevede un'analisi approfondita dei dati di basso livello del workload reale e sintetico. Essi devono essere oppurtunamente caratterizzati per essere infine confrontati statisticamente. Per farlo si utilizzano dei test statistici meglio descritti successivamente.
\end{enumerate}
Le tre fasi possono essere rappresentate graficamente come nella successiva figura.

\begin{figure}[H]
	\centering
	\includegraphics[width=0.6\textwidth]{img/hw3/Overview.png}
	\caption{\textit{Overview WL Characterization}}
\end{figure}

Per tutte le fasi il server occorre configurarlo allo stesso modo. In particolare si è utilizzato lo stesso Web Server descritto nel \textit{Capitolo 2} ma con una diminuzione di prestazioni solo a scopo didattico.

\section{Real-field Workload}
Per simulare quanto il più possibile un workload reale. Inoltre i dati di alto e basso livello devono essere presi contemporaneamente nel client e nel server.
\subsection{Server}
Il server contiene 10 file di diversa dimensione. I file sono stati scelti tutti dello stesso tipo (file di testo) solo per dimensionarli a piacimento. Nulla vieta però di utilizzare file di tipologie diverse (immagini, documenti, audio, etc.).
\\Essi sono stati dimensionati differenziando i file tra loro di 50 KB e partendo da un minimo di 50 KB.

\subsubsection{Parametri di basso livello}
Il web server è una macchina virtuale linux. Esistono dunque molti tool in grado di collezionare i parametri di caratteristici del sistema. In questo caso è stato utilizzato il tool \textbf{vmstat}. Esso offre inoltre la funzionalità di eseguire un campionamento dei parametri ad una frequenza e durata prefissata, tramite l'apposito comando eseguibile da terminale:
\begin{minted}[framesep = 1mm,
	fontsize = \footnotesize,
	breaklines,
	]{PYTHON}
	vmstat -n 1 400
\end{minted}
Il primo parametro "1" indica il periodo di campionamento in secondi, mentre il secondo parametro "400" indica la durata totale di esecuzione in secondi. L'output poi può essere semplicemente salvato in un file di testo.
\\Esso permette di monitorare parametri come:
\begin{itemize}
	\item \textit{free}, quantità di memoria libera.
	\item \textit{in}, numero di interruzioni al secondo
	\item \textit{us}, tempo trascorso dalla CPU nell'eseguire codice non-kernel
	\item \textit{sy}, tempo trascorso dalla CPU nell'eseguire codice kernel
	\item \textit{id}, tempo trascorso dalla CPU nello stato di idle
\end{itemize}
I quali poi devono essere opportunamente studiati.

\subsection{Client - JMeter}
La simulazione degli utenti che fanno accesso al server è stata possibile tramite il tool JMeter, già descritto nei capitoli precedenti. 
\\In particolare sono stati realizzati tre Thread Group ognuno composto da 10 Thread (l'equivalente di 10 utenti) con una durata di simulazione pari a 2 min ciascuno. Ogni gruppo contiene 10 richieste riferite alle 10 risorse disponibili nel web server. Esse vengono poi eseguite in modo casuale tramite un apposito controller. 
\begin{figure}[H]
	\centering
	\includegraphics[width=0.4\textwidth]{img/hw3/jmeter_reale.png}
	\caption{\textit{Configurazione di JMeter per la simulazione di un workload reale}}
\end{figure}
Ogni gruppo inoltre ha un suo specifico carico. In questo caso si ha:
\begin{itemize}
	\item \textbf{TG1} : 400 richieste al minuto
	\item \textbf{TG2} : 550 richieste al minuto
	\item \textbf{TG3} : 700 richieste al minuto
\end{itemize}
Essi vengono poi eseguiti in sequenza e non in parallelo. Questo perché si possono creare possibili conflitti sulle risorse, dati dal fatto che ogni gruppo richiede le stesse risorse degli altri. 
\subsubsection{Parametri di alto livello}
I parametri di alto livello possono essere collezionati direttamente tramite il tool JMeter e salvati in formato \textit{.cvs}. Non sono necessari dunque programmi esterni. I parametri utili ai fini dell'analisi sono:
\begin{itemize}
	\item \textbf{Timestamp}, l'istante di tempo in cui viene effettuata la corrispettiva richiesta (in millisecondi)
	\item \textbf{elapse}, inteso come Response Time
	\item \textbf{label}, contiene l'informazione categorica della richiesta effettuata.
	\item \textbf{bytes}, numero di byte ricevuti tramite la relativa richiesta.
	\item \textbf{sentBytes}, numero di byte inviati per effettuare la richiesta.
	\item \textbf{latency}
	\item \textbf{connect}, tempo di connessione misurato per effettuare l'handshake TCP (in millisecondi).
\end{itemize}

\subsection{Workload Characterization}
Le misure vengono effettuate correttamente avviando prima \textit{vmstat} nel server e in seguito JMeter sul client in modo che i dati vengono salvati contemporaneamente nel lato client (alto livello) e nel lato server (basso livello). Al termine della simulazione quindi ci si ritrovano due file di dati.

\subsubsection{Parametri di alto livello}
I parametri di alto livello vanno incontro alla procedura di filtraggio, PCA e Clustering per ridurne la dimensionalità.
\\Essi appaiono nel seguente modo:
\begin{figure}[H]
	\centering
	\includegraphics[width=0.8\textwidth]{img/hw3/alto_livello_esempio.png}
	\caption{\textit{Parametri di alto livello utili ai fini dell'analisi}}
\end{figure}
\hrule
\vspace{0.3cm}
La fase di filtraggio non prevede nessuna azione di modifica del dataset.
\\Sul dataset originale quindi deve essere effettuata la PCA per cercare di ridurne la dimensionalità senza perdere troppa varianza. Bisogna soprattutto considerare che per questi parametri la fase di Clustering è molto importante poiché racchiude le informazioni principali per costruire il workload sintetico.
\vspace{0.3cm}
\hrule
\vspace{0.3cm}
Tramite la PCA sono state scelte tutte le componenti principali, mantenendo una varianza del 100\%.
\begin{figure}[H]
	\centering
	\includegraphics[width=0.6\textwidth]{img/hw3/autovalori.png}
	\caption{\textit{Analisi della varianza tramite autovalori}}
\end{figure}
Sulla base di queste può essere effettuato il clustering gerarchico.
\vspace{0.3cm}
\hrule
\vspace{0.3cm}
Il numero di cluster rappresenta il numero di richieste del workload sintetico, poiché in ogni cluster viene scelto un elemento rappresentativo di esso stesso. A tal proposito quindi il numero di cluster non deve essere maggiore del numero di \textit{HTTP Request} totali utilizzate durante la simulazione (in questo caso 30) e non deve essere un numero molto elevato. Al tempo stesso però non si deve perdere molta varianza a causa della clusterizzazione. 
\\La via più semplice è quella di effettuare delle prove scegliendo un numero di cluster minore della metà (in questo caso minore di 15) e valutare per ogni numero quanta varianza si perde.
\\Partendo da 6 componenti principali si può scegliere un numero di cluster variabile e calcolare la devianza persa per ogni valore.
\begin{center}
	\begin{tabular}{|c|c|c|c|c|c|}
		\hline
		\textbf{6 Cluster} & \textbf{8 Cluster} & \textbf{10 Cluster} &\textbf{12 Cluster} \\
		\hline
		35\% & 27\%& 21.5\% & 17\% \\
		\hline
	\end{tabular}
\end{center}
La scelta ricade su 10 cluster in modo da avere un workload sintetico abbastanza ristretto e una perdita di varianza non troppo elevato.
\\Per scegliere gli elementi rappresentativi di un cluster si può ricorrere a vari metodi:
\begin{itemize}
	\item Il punto più centrale possibile
	\item Il punto in cui un valore categorico si ripete più volte. Applicabile però solo se il dataset ha un parametro categorico in un insieme limitato di valori.
	\item Casualmente
	\item Il punto che si avvicina il più possibile alla media del cluster
	\item Etc.
\end{itemize}



\subsubsection{Parametri di basso livello}


\section{Synthetic Workload}
A partire dalla clusterizzazione di alto livello, identificati gli elementi rappresentativi di ogni cluster, si deve rifare la simulazione ma con il workload sintetico.
\\Il dataset in esame è composto da un parametro categorico che rappresenta la richiesta effettuata (risorsa e utente) facendo parte di un insieme molto limitato. La scelta può quindi ricadere sulla seconda possibilità.
\\A tal proposito si può calcolare una tabella che per ogni cluster indica il numero di ricorrenze del valore del parametro categorico.
\begin{figure}[H]
	\centering
	\includegraphics[width=\textwidth]{img/hw3/cluster_label.png}
	\caption{\textit{Tabella che associa ad ogni cluster il numero di punti con una determinata \textit{label}}}
\end{figure}
La matrice che compone la tabella è una matrice 10x30 e bisogna calcolare il massimo di riga per ogni riga. Inoltre se il massimo di riga è associato ad una \textit{label} già selezionata in precedenza, allora si deve scegliere il secondo massimo nella riga e così via. Si può automatizzare il tutto tramite uno script MATLAB:
\begin{minted}[framesep = 1mm,
	fontsize = \footnotesize,
	breaklines,
	]{MATLAB}
%% Dati
[data, txt] = xlsread('label-cluster 10');
data_filter = data(:, 3:end); 
txt_filter = txt(:, 3:end)';

%% Ricerca centroidi
[r,c] = size(data_filter);
max_list = zeros(1,r);  % Lista dei massimi
max_index = zeros(1,r); % Lista degli indici dei massimi

%Inizializzo vettore degli indici
for i=1:r
	max_index(i) = -1;
end

for i=1:r
	[temp_v, temp_i] =  max(data_filter(i,:));
	while ismember(temp_i,max_index)
		data_filter(i,temp_i) = -1;
		[temp_v, temp_i] =  max(data_filter(i,:));
	end
	max_list(i) = temp_v;
	max_index(i) = temp_i;
end

%% Stampa risultati
sort(txt_filter(max_index))
\end{minted}
Il risultato dello script è la lista delle \textit{label} che identificano il workload sintetico.
\begin{enumerate}
	\item HTTP Request 1 : TG1 con risorsa \textit{200k.txt}
	\item HTTP Request 11 : TG2 con risorsa \textit{50k.txt}
	\item HTTP Request 17 : TG2 con risorsa \textit{350k.txt}
	\item HTTP Request 21 : TG3 con risorsa \textit{50k.txt}	
	\item HTTP Request 22 : TG3 con risorsa \textit{100k.txt}		
	\item HTTP Request 23 : TG3 con risorsa \textit{150k.txt}		
	\item HTTP Request 25 : TG3 con risorsa \textit{250k.txt}		
	\item HTTP Request 27 : TG3 con risorsa \textit{350k.txt}
	\item HTTP Request 28 : TG3 con risorsa \textit{400k.txt}			
	\item HTTP Request 29 : TG3 con risorsa \textit{450k.txt}		
\end{enumerate}

\subsection{Server}
Il server non deve essere assolutamente modificato. Tutte le configurazioni effettuate per il workload reale rimangono invariate

\subsubsection{Parametri di basso livello}
I parametri di basso livello devono essere collezionati allo stesso modo utilizzato nel workload reale. Essi devono essere confrontati con i parametri di basso livello salvati durante la simulazione del workload reale.

\subsection{Client - JMeter}
Il client deve, a questo punto, simulare le nuove richieste applicando il workload sintetico ricavato con l'analisi. Anche in questo caso la configurazione di JMeter non deve essere modificata, tranne che per le richieste.
\begin{figure}[H]
	\centering
	\includegraphics[width=0.4\textwidth]{img/hw3/jmeter_sintetico.png}
	\caption{\textit{Configurazione di JMeter per il workload sintetico}}
\end{figure}

\subsubsection{Parametri di alto livello}
I parametri di alto livello possono anche non essere collezionati poiché non servono per ulteriori analisi. Per completezza si possono salvare tramite lo stesso JMeter usato per la simulazione.


\subsection{Workload Characterization}
\subsubsection{Parametri di basso livello}

\section{Data Validation}
Si hanno tutte le informazioni per confrontare i parametri di basso livello caratterizzati (workload reale e sintetico).
\\La procedura per la validazione è molto semplice:
\begin{enumerate}
	\item Normalità verificata. Se i due dataset provengono da una distribuzione normale allora si possono eseguire test parametrici per la validazione. In particolare si possono usare vari tipi di test statistici anche in base all'omostedasticità.
	\begin{enumerate}
		\item Omostedasticità verificata. Se i due dataset sono omostedastici allora si possono utilizzare test sulla base di questa condizione verificata.
		\item Omostedasticità non verificata. Se i due dataset non rispettano la proprietà di omestedasticità allora bisogna utilizzare test che si basano su tale condizione non verificata.
	\end{enumerate}
	\item Nomarlità non verificata. Se i due dataset non provengono da una distribuzione normale allora si devono usare necessariamente test statistici non parametrici per la validazione.
\end{enumerate}

\subsection{Normalità}
Per verificare se un campione proviene da una popolazione con distribuzione normale, ci si può affidare a test visivi oppure a test statistici analitici.
\subsubsection{Test Visivo}
Visivamente si può capire se un campione proviene da una popolazione con distribuzione normale effettuando un grafico dei quantili del campione rispetto ai quanti di una distribuzione normale.
\\Ad esempio prendendo una componente principale del workload reale (dopo la caratterizzazione) si può effettuare un grafico dei quantili:
\begin{figure}[H]
	\centering
	\includegraphics[width=0.8\textwidth]{img/hw3/test_visivo.png}
	\caption{\textit{Grafico Quantili-Quantili della prima componente principale del workload reale caratterizzato}}
\end{figure}
come si può notare il campione non proviene da una distribuzione normale.
\subsubsection{Test analitico}
Un test analitico è il test di Kolmogorov-Smirnov. Esso si basa sull'ipotesi nulla $H_0$:
\begin{equation*}
	H_0 : N(0,1) 
\end{equation*}
In MATLAB esiste una funzione già definita per eseguire questo tipo di test. Esso fornisce in output il risultato del test (se $H_0$ viene rigettata o meno) con il relativo \textit{P-Value}.